{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Web  scraping,  also  called web  data  mining or web  harvesting, is  the  process  of constructing an agent which can extract, parse, download and organize useful information from the web automatically.\n",
    "\n",
    "#### The  information  extracted  using  web scraping  can  be  used  to  replicate  in some other website or can be used to perform data analysis. For example the data elements can be names, address, price etc. \n",
    "\n",
    "#### Web scraping automatically extracts data and presents it in a format you can easily make sense of."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Some of the important uses of web scraping are discussed here:\n",
    "\n",
    "#### E-commerce Websites:Web scrapers can collect the data specially related to the price of a specific product from various e-commerce websites for their comparison.\n",
    "\n",
    "#### Content Aggregators:Web scraping is used widely by content aggregators like news aggregators and job aggregators for providing updated data to their users.\n",
    "\n",
    "#### Marketing andSales Campaigns:Web scrapers can be used to get the data like emails, phone number etc.for sales and marketing campaigns.\n",
    "\n",
    "#### Search Engine Optimization (SEO):Web scraping is widely used by SEO tools like SEMRush, Majestic etc. to tell business how they rank for search keywords that matter to them.\n",
    "\n",
    "#### Data  for Machine Learning Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We are going to use Python as our scraping language, together with a simple and powerful library, BeautifulSoup."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Rules-\n",
    "#### You should check a website’s Terms and Conditions before you scrape it. Be careful to read the statements about legal use of data. Usually, the data you scrape should not be used for commercial purposes.\n",
    "#### Do not request data from the website too aggressively with your program (also known as spamming), as this may break the website. Make sure your program behaves in a reasonable manner (i.e. acts like a human). One request for one webpage per second is good practice.\n",
    "#### The layout of a website may change from time to time, so make sure to revisit the site and rewrite your code as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import requests # pip install requests \n",
    "from bs4 import BeautifulSoup  # pip install bs4 / conda install bs4 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#using the request model , we get the 'get' function \n",
    "#provides access to the webpage  provided as an argument in this function \n",
    "result=requests.get(url=\"https://timesofindia.indiatimes.com/\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "200\n"
     ]
    }
   ],
   "source": [
    "#To make sure that the website is accessible , we can ensure we get a 200 OK response \n",
    "#to indicate that the page is indeed present \n",
    "print(result.status_code) #HTTP status codes can be checked from wikipedia "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'x-amz-id-2': 'xnk77DVG29uQhIsg54QsUOyHldQglK6QGsMwYszx7OyXMeLlB4JHhJVX7zUHXbTeA/xpb8onVZc=', 'x-amz-request-id': '0F4RX6TBVMYASRE6', 'Last-Modified': 'Thu, 03 Mar 2022 07:10:36 GMT', 'ETag': '\"f603278a95b773c306b3d680bdc7dc33\"', 'Content-Encoding': 'gzip', 'Accept-Ranges': 'bytes', 'Content-Type': 'text/html; charset=utf-8', 'Server': 'AmazonS3', 'Content-Length': '116699', 'Vary': 'Accept-Encoding', 'Expires': 'Thu, 03 Mar 2022 07:11:27 GMT', 'Cache-Control': 'max-age=0, no-cache, no-store', 'Pragma': 'no-cache', 'Date': 'Thu, 03 Mar 2022 07:11:27 GMT', 'Connection': 'keep-alive', 'Access-Control-Max-Age': '86400', 'Access-Control-Allow-Credentials': 'false', 'Access-Control-Allow-Headers': 'Origin,X-Requested-With,Content-Type,Accept', 'Access-Control-Allow-Methods': 'GET,POST', 'Strict-Transport-Security': 'max-age=86400'}\n"
     ]
    }
   ],
   "source": [
    "print(result.headers)  #checking the HTTP header of the website to verify that indeed accessed correct page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "content=result.text #let us store the page content of the website accessed from requests to a variable using .text /.content "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now that we have the content stored ,we will use the bs4 module to parse and process the source.\n",
    "# we create a bs4 object based on source variable.\n",
    "soup=BeautifulSoup(content,\"html.parser\") # bs4 is used to parse and return individual data points from different HTML tags "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "News - Latest News, Breaking News, Bollywood, Sports, Business and Political News | Times of India\n"
     ]
    }
   ],
   "source": [
    "print(soup.title.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "headlines=soup.find('div',class_=\"_3MUkE\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ukraine crisis live: 19 evacuation flights to bring back 3,726 Indians today\n"
     ]
    }
   ],
   "source": [
    "print(headlines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_news=soup.find('div',class_='_2r4Y_ grid_wrapper') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list_news[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_items=list_news.findAll('div',class_='col_l_6')\n",
    "news_item=[]\n",
    "list_items=list_items[0:15]\n",
    "for news in list_items:\n",
    "    item=news.find('figcaption')\n",
    "    try:\n",
    "        news_item.append(item.text)\n",
    "    except:\n",
    "        news_item.append('No text')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['No report of Indian students being held hostage in Ukraine: MEA',\n",
       " 'Why are Chechens fighting for both Ukraine and Russia?',\n",
       " 'UP polls live: BJP will win over 80% seats, says Yogi',\n",
       " \"US recalls cable saying India, UAE in 'Russia’s camp': Report\",\n",
       " 'How Indians fleeing Ukraine ran into racism',\n",
       " \"Explained in charts: BJP's dominance in UP Phase 6 seats in 2017\",\n",
       " 'What is the chain of command for potential Russian nuclear strikes?',\n",
       " 'Asus 8Z vs OnePlus 9RT vs Xiaomi 11T Pro 5G',\n",
       " 'Empowering career growth with blended education',\n",
       " 'Experience seamless working on these powerful laptops!',\n",
       " 'Building personal brands with social commerce',\n",
       " \"PM Modi to participate in Quad Leaders' meet amid Ukraine crisis\",\n",
       " 'WhatsApp Group vs WhatsApp Broadcast: Difference',\n",
       " \"Covid live: India's active cases stand at 0.18%\",\n",
       " 'What are 360-degree parking cameras in cars']"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "news_item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# second approach \n",
    "\n",
    "news=soup.findAll('div',class_='col_l_6')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "list=[]\n",
    "for new in news:\n",
    "    try:\n",
    "        item=new.find('a',class_='_3SqZy').text\n",
    "    except:\n",
    "        item='-'\n",
    "    list.append(item) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "44"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "# list "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scraping Imdb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = []\n",
    "\n",
    "page_list = [1, 51, 101, 151, 201] # 5 pages and each page has 50 movies which results to 250 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_divs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for page in page_list: # page = 1 \n",
    "#     print(page)\n",
    "    url = f\"https://www.imdb.com/search/title/?groups=top_250&sort=user_rating,desc&start={page}&ref_=adv_nxt\"\n",
    "    response = requests.get(url) # request to get url \n",
    "    data = response.text # .text to capture the reponse \n",
    "    soup = BeautifulSoup(data, 'html.parser')  # creating soup object to parse through the html tags of response text \n",
    "    data_divs = soup.find_all('div', {'class' : 'lister-item-content'})\n",
    "    \n",
    "    for data_div in data_divs:\n",
    "        data_dict = dict()\n",
    "        data_dict['Rank'] = data_div.find('h3', {'class' : 'lister-item-header'}).text.split('\\n')[1] # '1','The Shawshank redemption','1994'\n",
    "        data_dict['Movie'] = data_div.find('h3', {'class' : 'lister-item-header'}).text.split('\\n')[2]\n",
    "        try:\n",
    "            data_dict['Year'] = data_div.find('h3', {'class' : 'lister-item-header'}).text.split('\\n')[3]\n",
    "        except:\n",
    "            data_dict['Year'] = None\n",
    "        try:\n",
    "            data_dict['Certificate'] = data_div.find('span', {'class' : 'certificate'}).text\n",
    "        except:\n",
    "            data_dict['Certificate'] = None\n",
    "        data_dict['Runtime'] = data_div.find('span', {'class' : 'runtime'}).text\n",
    "        data_dict['Genre'] = data_div.find('span', {'class' : 'genre'}).text\n",
    "        data_dict['Rating'] = float(data_div.find('strong').text)\n",
    "        data_dict['Movie description']=data_div.find('p',class_='text-muted').text\n",
    "        data_dict['Gross Value']=data_div.find('span',{'name':'nv'}).text \n",
    "        data_list.append(data_dict) # List of dicts "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "df = pd.DataFrame(data_list)\n",
    "df.head() # Dataframe is a list of dictionaries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df[['Rank','Movie','Certificate','Rating','Movie description','Genre','Runtime','Year','Gross Value']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''clean the data using regex'''\n",
    "import re "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean_movie_name(movie):\n",
    "#     movie_first_clean=re.sub(r\"(\\d)(.)\",'',movie)\n",
    "#     movie_name=re.sub(r\"[()]\",'',movie_first_clean)\n",
    "#     return movie_name.strip()\n",
    "\n",
    "# movie= '\\n1.\\nThe Shawshank Redemption\\n(1994)\\n'\n",
    "# print(clean_movie_name(movie))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df['Movie_title']=df['Movie'].apply(clean_movie_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_genre(genre):\n",
    "    genre=re.sub(r\"\\n\",'',genre)\n",
    "    return genre.strip() \n",
    "\n",
    "# genre= '\\nAction, Crime, Drama'\n",
    "# print(clean_genre(genre))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['genre']=df['Genre'].apply(clean_genre) # creating a column called 'genre' and applying the original col 'Genre'on the function clean_genre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_year(year):\n",
    "    year=re.sub(r\"[()]\",'',year)\n",
    "    return year.strip()\n",
    "\n",
    "# year= '(1994)'\n",
    "# print(clean_year(year))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['year']=df['Year'].apply(clean_year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Rank                  object\n",
       "Movie                 object\n",
       "Certificate           object\n",
       "Rating               float64\n",
       "Movie description     object\n",
       "Genre                 object\n",
       "Runtime               object\n",
       "Year                  object\n",
       "Gross Value           object\n",
       "genre                 object\n",
       "year                  object\n",
       "dtype: object"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "df= df[['Rank','Movie', 'year', 'genre','Runtime','Certificate','Rating']] # selecting cols to store back in dataframe and ignoring others "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"Imdb_top_250.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Another example \n",
    "\n",
    "repository- https://github.com/kayode-adechinan/pyscrap to create local server for scraping "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "page = requests.get(\"http://localhost:8000/products.html\")\n",
    "soup = BeautifulSoup(page.text, 'html.parser') # can specify the response object as .content / .text \n",
    "# print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/a.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product A</p>\n",
      "<p><strong> $22.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/b.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product B</p>\n",
      "<p><strong> $24.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/c.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product C</p>\n",
      "<p><strong> $19.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/d.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product D</p>\n",
      "<p><strong> $32.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/e.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product E</p>\n",
      "<p><strong> $21.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/f.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product F</p>\n",
      "<p><strong> $13.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/g.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product G</p>\n",
      "<p><strong> $22.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/h.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product H</p>\n",
      "<p><strong> $27.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/i.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product I</p>\n",
      "<p><strong> $23.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/a.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product J</p>\n",
      "<p><strong> $31.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/b.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product K</p>\n",
      "<p><strong> $42.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>, <li class=\"span4\">\n",
      "<div class=\"thumbnail\">\n",
      "<a class=\"overlay\" href=\"product_details.html\"></a>\n",
      "<a class=\"zoomTool\" href=\"product_details.html\" title=\"add to cart\"><span class=\"icon-search\"></span> QUICK VIEW</a>\n",
      "<a href=\"product_details.html\"><img alt=\"\" src=\"assets/img/c.jpg\"/></a>\n",
      "<div class=\"caption cntr\">\n",
      "<p>Product L</p>\n",
      "<p><strong> $15.00</strong></p>\n",
      "<h4><a class=\"shopBtn\" href=\"#\" title=\"add to cart\"> Add to cart </a></h4>\n",
      "<div class=\"actionList\">\n",
      "<a class=\"pull-left\" href=\"#\">Add to Wish List </a>\n",
      "<a class=\"pull-left\" href=\"#\"> Add to Compare </a>\n",
      "</div>\n",
      "<br class=\"clr\"/>\n",
      "</div>\n",
      "</div>\n",
      "</li>]\n"
     ]
    }
   ],
   "source": [
    "def retrieve_all_products():\n",
    "    print(soup.find_all('li', class_='span4')) # alternative syntax to this --> {'class':'span4'}\n",
    "\n",
    "if __name__ == '__main__': \n",
    "    retrieve_all_products()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " $22.00\n",
      "22.00\n"
     ]
    }
   ],
   "source": [
    "def retrive_first_product_price():\n",
    "    all_products = soup.find_all('li', class_='span4')\n",
    "    product_one = all_products[0]\n",
    "    product_one_price = product_one.find(\"strong\")\n",
    "    print(product_one_price.get_text()) # .text \n",
    "    print(product_one_price.get_text().strip().strip('$'))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    retrive_first_product_price()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we get all products. Then we take the result and upon this, we look for the price. This one is inside a strong tag. After fiding the price we display it. We can also removed $ character. As you see, you can search element based on previous result's search. Unlike find_all method that returns a list of elements or an empty list, find method returns a single element or None."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose we want to compare our products with their price as criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Product A': '$22.00', 'Product B': '$24.00', 'Product C': '$19.00', 'Product D': '$32.00', 'Product E': '$21.00', 'Product F': '$13.00', 'Product G': '$22.00', 'Product H': '$27.00', 'Product I': '$23.00', 'Product J': '$31.00', 'Product K': '$42.00', 'Product L': '$15.00'}\n"
     ]
    }
   ],
   "source": [
    "def lazy_comparator():\n",
    "    all_products = soup.find_all('li', class_='span4')\n",
    "    products = {}\n",
    "    for product in all_products:\n",
    "        products[product.find(\"p\").get_text().strip()] = product.find(\"strong\").get_text().strip()\n",
    "    print(products)\n",
    "#     print (sorted([(v, k) for k, v in products.items()]))\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    lazy_comparator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference links- https://realpython.com/beautiful-soup-web-scraper-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Linkedin_Scraper\n",
    "\n",
    "# import requests \n",
    "# from bs4 import BeautifulSoup\n",
    "# import pandas as pd\n",
    "# import re\n",
    "# from time import sleep \n",
    "\n",
    "# ids=[]\n",
    "# titles=[]\n",
    "# urls=[]\n",
    "# comp_names=[]\n",
    "# locations=[]\n",
    "# dates=[]\n",
    "# jd=[]\n",
    "# for i in range(0,100,25): # 100 for 4 pages , if you want to return 1000 jobs , run the loop till 1000 \n",
    "#     url='https://www.linkedin.com/jobs/search/'\n",
    "\n",
    "#     params={\n",
    "#         'f_TPR':'r86400',\n",
    "#         'geoId':'105214831', \n",
    "#         'keywords':'full stack engineer',\n",
    "#         'location':'India',\n",
    "#         'start':''\n",
    "#     }\n",
    "#     params['start']=str(i)\n",
    "#     response=requests.get(url=url,params=params)\n",
    "#     # print(response) # 200 success response\n",
    "#     soup=BeautifulSoup(response.text,'html.parser')\n",
    "#     job_items=soup.find('ul',class_='jobs-search__results-list')\n",
    "#     job_ids=[i['data-entity-urn'] for i in job_items.findAll('div',class_='base-card base-card--link base-search-card base-search-card--link job-search-card')]\n",
    "#     job_title=[i.text.strip() for i in job_items.findAll('h3',class_='base-search-card__title')]\n",
    "#     job_url=[url['href'] for url in job_items.findAll('a',class_='base-card__full-link')]\n",
    "#     descp=[]\n",
    "#     for url in job_url: # 25 times \n",
    "#         sleep(1)\n",
    "#         response=requests.get(url) \n",
    "#         soup=BeautifulSoup(response.text,'html.parser')\n",
    "#         try:\n",
    "#             description=soup.find('div',class_='description__text description__text--rich').text.strip()\n",
    "#             descp.append(description)\n",
    "#         except:\n",
    "#             descp.append('NOT FOUND')\n",
    "#     company=[comp.text.strip() for comp in job_items.findAll('h4',class_='base-search-card__subtitle')] \n",
    "#     location=[loc.text.strip() for loc in job_items.findAll('span',class_='job-search-card__location')]\n",
    "#     date_posted=[date.text.strip() for date in job_items.findAll('time',class_='job-search-card__listdate--new')]\n",
    "#     ids.extend(job_ids)\n",
    "#     titles.extend(job_title)\n",
    "#     urls.extend(job_url)\n",
    "#     comp_names.extend(company)\n",
    "#     locations.extend(location)\n",
    "#     dates.extend(date_posted) \n",
    "#     jd.extend(descp)\n",
    "    \n",
    "# dict={\n",
    "#     'Job_ID':ids,\n",
    "#     'Title':titles,\n",
    "#     'Job_url':urls,\n",
    "#     'Company':comp_names,\n",
    "#     'Location':locations,\n",
    "#     'Time Posted':dates,\n",
    "#     'JD':jd\n",
    "# }\n",
    "\n",
    "# df=pd.DataFrame.from_dict(dict,orient='index')\n",
    "# df = df.transpose()\n",
    "# # df\n",
    "\n",
    "# def clean_id(ids):\n",
    "#     ids_=re.sub('urn:li:jobPosting:','',ids)\n",
    "#     return ids_\n",
    "    \n",
    "# df['Job_ID']=df['Job_ID'].apply(clean_id)\n",
    "\n",
    "# def clean_descp(descp):\n",
    "#     y=re.sub('\\n+','',descp)\n",
    "#     z=re.sub('Show more                Show less','',y)\n",
    "#     return z.strip()\n",
    "# df['JD']=df['JD'].apply(clean_descp)\n",
    "\n",
    "# # df.head()\n",
    "# df[['Job_ID']]=df[['Job_ID']].apply(pd.to_numeric) # converting data type of one column into another type \n",
    "# df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
